import numpy as np
import nibabel as nib
import fnmatch, os, glob
from copy import deepcopy
from utils.pickles import arr_to_hdf5, hdf5_to_arr


class Dataset:

    def __init__(self, fpath):
        self.fpath = fpath
        self.data = []
        self.num_not_nan = []
        self.non_nan_mask = []


def get_repdata(fpath, subj_regex, condition_regex, file_ext='.nii', reps=6, subjs=[], roi_data=False, save_num_nonnan=False):

    """

    Returns z-scored data, per each repetition, across subjects given a specific condition ('Intact', 'Scrambled-Fixed', etc.)

    Optional feature that saves the number of non-nan data per voxel.

    :param fpath: string
        Path to data directory.

    :param subj_regex: string
        Regular expression identifying all data file names.

    :param condition_regex: string
        Regular expression identifying all data files by specific condition (e.g. 'Intact').

    :param file_ext: string, optional
        File extension of data files.

    :param reps: int, optional
        Number of repetitions to include.

    :param subjs: list, optional
        Option for manually specifying subjects to be considered in z-scoring.

    :param roi_data: boolean, optional
        Uses ROI data instead if set to True.

    :param save_num_nonnan: boolean, optional
        Saves the number of non-nan data per voxel if set to True.

    :return D: ndarray
        Returns z-scored data across subjects for each repetition.

    """

    if len(subjs) > 0:
        subjects = deepcopy(subjs)
    else:
        subjects = [subjdir for subjdir in os.listdir(fpath) if fnmatch.fnmatch(subjdir, subj_regex)]

    D = []
    D_num_not_nan = []


    for rep in range(reps):

        D_rep = []
        D_not_nan = []

        for subj in range(len(subjects)):

            fname = glob.glob(fpath + subjects[subj] + '/' + condition_regex + str(rep + 1) + file_ext)[0]

            assert len(fname) == 1, "More than one file found for subject " + subjects[subj]

            if roi_data:
                rep_z = hdf5_to_arr(fname)

            else:

                rep_z = nib.load(fname).get_fdata()
                rep_z = (rep_z - np.mean(rep_z, axis=3)[:, :, :, np.newaxis])/(np.std(rep_z, axis=3)[:, :, :, np.newaxis])

            D_rep.append(rep_z)
            non_nan = np.array(~np.isnan(rep_z))
            D_not_nan.append(non_nan)

        D_not_nan = np.sum(D_not_nan, axis=0)

        D_rep = np.nanmean(D_rep, axis=0)
        D_rep = (D_rep - np.nanmean(D_rep, axis=3)[:, :, :, np.newaxis])/(np.nanstd(D_rep, axis=3)[:, :, :, np.newaxis])

        D.append(D_rep.T)
        D_num_not_nan.append(D_not_nan.T)

    if save_num_nonnan:
        np.save('num_non-nan_by_voxel.npy', D_num_not_nan)

    return D

def get_maskdata(fpath):

    """
    Loads MNI map returns a transposed boolean mask of voxels that are included in the map.

    :param fpath: string
        File path of MNI map.

    :return voxels in map: ndarray
        Transposed boolean mask of voxels that have data in the MNI map.

    """

    return np.asarray(nib.load(fpath).get_fdata().astype(bool)).T

def get_non_nan_mask(non_nan_count, mask, min_subjs=15):

    """

    Generates voxel x voxel x voxel boolean map in which a True value represents a voxel that had data for at least
    the minimum number of subjects and is a voxel in the MNI mask.

    :param non_nan_count: array_like
    Number of subjects represented in each element. Generated by get_repdata.

    :param mask: array_like
    MNI map of data.

    :param min_subjs: int, optional
    Minimum number of subject data per element.

    :return non_nan_mask: ndarray

    Boolean map of the intersection of the minimum number of data points and MNI map.

    """

    non_nan_mask = np.asarray(deepcopy(non_nan_count))

    # get min number of subject data per voxel over repititions and then again over TRs #
    non_nan_mask = np.min(np.min(non_nan_mask, axis=0), axis=0)

    return (non_nan_mask > (min_subjs - 1)) * mask

def get_data_pval(voxel_data, p_vals, p=.05):

    """
    Generates voxel x voxel x voxel map of elements masked out by significant values only.

    :param voxel_data: array_like
        Data stored as a voxel x voxel x voxel map.

    :param p_vals: array_like
        P-values corresponding to voxel_data.

    :param p: float, optional
        Threshold for significance.

    :return significant_values: ndarray
        Data masked out for significant values only.

    """

    masked_data = np.asarray(deepcopy(voxel_data))

    return masked_data * (p_vals < p)


def get_slight_clusters(voxel_data):

    """

    Generates a labeled ROI cluster map.

    :param voxel_data:
        Data stored as a voxel x voxel x voxel map.

    :return labeled_ROIs: ndarray
        Labled ROI map.

    """

    from scipy.ndimage.measurements import label

    voxel_data[np.isnan(voxel_data)] = 0

    return label(voxel_data)


def get_rois(fpath, subj_regex, condition_regex, roi_mask_fpath, file_ext='.nii', reps=6):

    """

    Saves z-scored dilated ROIs, per each repetition, given a specific condition
    (e.g. 'Intact', 'Scrambled-Fixed', etc.)

    :param fpath: string
        Path to data directory.

    :param subj_regex: string
        Regular expression identifying all data file names.

    :param condition_regex: string
        Regular expression identifying all data files by specific condition (e.g. 'Intact').

    :param roi_mask_fpath: string
        Filepath to ROI mask.

    :param file_ext: string, optional
        File extension of data files.

    :param reps: int, optional
        Number of repetitions to include.

    """

    subjects = [subjdir for subjdir in os.listdir(fpath) if fnmatch.fnmatch(subjdir, subj_regex)]

    roi_mask = nib.load(roi_mask_fpath).get_fdata()
    n_rois = int(np.amax(roi_mask))

    for roi in range(1, n_rois + 1):
        mask = roi_mask == roi
        z_scored_ds = []

        for subj in range(len(subjects)):

            reps_data = []

            for rep in range(reps):
                assert len(
                    glob.glob(fpath + subjects[subj] + '/' + condition_regex + str(rep + 1) + '*' + file_ext)) == 1

                fname = glob.glob(fpath + subjects[subj] + '/' + condition_regex + str(rep + 1) + '*' + file_ext)[0]

                rep_data = nib.load(fname).get_fdata()

                rep_data = rep_data[mask.T, :]

                rep_data = (rep_data - np.mean(rep_data, axis=1)[:, np.newaxis]) / (
                np.std(rep_data, axis=1)[:, np.newaxis])
                reps_data.append(rep_data.T)

            z_scored_ds.append(reps_data)

        roi_data = np.array(z_scored_ds)
        arr_to_hdf5('dil_roi' + str(roi), data=roi_data)


def get_roidata(roi, subj_idxs, fpath_regex='dil_roi'):

    """

    Generates z-scored ROIs across subjects.

    Iteratively call this function after saving repetition z-scored ROIs in get_rois.

    :param roi: int or string
        Label of ROI.

    :param subj_idxs: list
        A list of indices corresponding to subjects included in z-scoring.

    :param fpath_regex: string, optional
        Regular expression identifying ROIs.

    :return D: ndarray
        Returns z-scored data across subjects' ROIs.

    """

    assert len(glob.glob(fpath_regex + str(roi) + '.*')) == 1

    fname = glob.glob(fpath_regex + str(roi) + '.*')[0]

    from utils.pickles import hdf5_to_arr

    D = np.array(hdf5_to_arr(fname))
    D = D[subj_idxs, :]
    D = np.nanmean(D, axis=0)
    D = (D - np.nanmean(D, axis=1)[:, np.newaxis]) / (np.nanstd(D, axis=1)[:, np.newaxis])

    return D